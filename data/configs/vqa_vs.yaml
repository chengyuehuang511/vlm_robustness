 # Copyright (c) 2022, salesforce.com, inc.
 # All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause

datasets:
  coco_vqa_vs: 
    # data_dir: ${env.data_dir}/datasets
    data_type: images # [images|videos|features]

    build_info:
      # Be careful not to append minus sign (-) before split to avoid itemizing
      annotations:
        train:
          url:
              - https://huggingface.co/datasets/QingyiSi/VQA-VS/resolve/main/VQA-VS/Training/Training-Ques.json?download=true
              # - https://huggingface.co/datasets/QingyiSi/VQA-VS/resolve/main/VQA-VS/Training/Training-Ques.json?download=true
              # - https://huggingface.co/datasets/QingyiSi/VQA-VS/resolve/main/VQA-VS/Training/Training-Ans.json?download=true
          storage:
              - /coc/pskynet4/bmaneech3/vlm_robustness/tmp/datasets/vqavs/train/combined_data.json
              # - /nethome/bmaneech3/flash/vlm_robustness/tmp/datasets/vqavs/train/train_questions.json
              # - /nethome/bmaneech3/flash/vlm_robustness/tmp/datasets/vqavs/train/train_annotations.json
        val:  # == test
          url: # don't forget answer list 
              - https://huggingface.co/datasets/QingyiSi/VQA-VS/resolve/main/VQA-VS/Val/Val-Ques.json?download=true
              - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/answer_list.json
              - https://huggingface.co/datasets/QingyiSi/VQA-VS/resolve/main/VQA-VS/Val/Val-Ques.json?download=true
              - https://huggingface.co/datasets/QingyiSi/VQA-VS/resolve/main/VQA-VS/Val/Val-Ans.json?download=true
          storage:
              - /coc/pskynet4/bmaneech3/vlm_robustness/tmp/datasets/vqavs/val/combined_data.json
              - /coc/pskynet6/chuang475/.cache/lavis/coco/annotations/answer_list.json
              - /coc/pskynet4/bmaneech3/vlm_robustness/tmp/datasets/vqavs/val/val_questions.json
              - /coc/pskynet4/bmaneech3/vlm_robustness/tmp/datasets/vqavs/val/val_annotations.json

        test:  # == test
          url:
              - https://huggingface.co/datasets/QingyiSi/VQA-VS/resolve/main/VQA-VS/IID-Test/IID-Test-Ques.json?download=true
              - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/answer_list.json
              - https://huggingface.co/datasets/QingyiSi/VQA-VS/resolve/main/VQA-VS/IID-Test/IID-Test-Ques.json?download=true
              - https://huggingface.co/datasets/QingyiSi/VQA-VS/resolve/main/VQA-VS/IID-Test/IID-Test-Ans.json?download=true
          storage:
              - /coc/pskynet4/bmaneech3/vlm_robustness/tmp/datasets/vqavs/test/combined_data.json
              - /coc/pskynet6/chuang475/.cache/lavis/coco/annotations/answer_list.json
              - /coc/pskynet4/bmaneech3/vlm_robustness/tmp/datasets/vqavs/test/test_questions.json
              - /coc/pskynet4/bmaneech3/vlm_robustness/tmp/datasets/vqavs/test/test_annotations.json
      images:
          storage: /coc/pskynet6/chuang475/.cache/lavis/coco/images/
